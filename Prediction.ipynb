{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striphtml(data):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(data))\n",
    "    return cleantext\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess_title(Title):\n",
    "    Title=striphtml(Title.encode('utf-8'))\n",
    "    Title=re.sub(r'[^A-Za-z0-9#+.\\-]+',' ',Title)\n",
    "    words=word_tokenize(str(Title.lower()))\n",
    "    Title=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c' or j=='r'))\n",
    "    return Title\n",
    "\n",
    "def preprocess_body(Body):\n",
    "    is_code=0\n",
    "    code_str=\"\"\n",
    "    if '<code>' in Body:\n",
    "        is_code = 1\n",
    "        code = re.findall('<code>(.*?)</code>', Body, flags=re.MULTILINE|re.DOTALL)\n",
    "        code_str = code_str.join(code)\n",
    "        \n",
    "    question=re.sub('<code>(.*?)</code>', '', Body, flags=re.MULTILINE|re.DOTALL)\n",
    "        \n",
    "    question=striphtml(question.encode('utf-8'))\n",
    "    question=re.sub(r'[^A-Za-z0-9#+.\\-]+',' ',question)\n",
    "    words=word_tokenize(str(question.lower()))\n",
    "    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c' or j=='r'))\n",
    "    \n",
    "    sent=\"\"\n",
    "    dup = dict()\n",
    "    for ch in code_str:\n",
    "        ch=ch.lower()\n",
    "        if(ch.isalpha()):\n",
    "            sent+=(ch)\n",
    "        if(ch in [' ','.','(',')','{','}','[',']','_','-','/','$','&','<','>',':',';','/','\\\\',\"'\",'?','!','@','#','%','^','*','+','=','|']):\n",
    "            if(ch not in dup):\n",
    "                dup[ch]=(int)(1)\n",
    "            if(dup.get(ch)<=5):\n",
    "                dup[ch]=(int)(dup.get(ch)+1)\n",
    "                sent+=\" \"+ch+\" \"\n",
    "            else:\n",
    "                sent+=\" \"\n",
    "\n",
    "    dup = dict()\n",
    "    sent1=\"\"\n",
    "    for ch in sent.split():\n",
    "        if(ch not in dup):\n",
    "            dup[ch]=(int)(1)\n",
    "        if(dup.get(ch)<=10):\n",
    "            dup[ch]=(int)(dup.get(ch)+1)\n",
    "            sent1+=\" \"+ch+\" \"\n",
    "        else:\n",
    "            sent1+=\" \"\n",
    "\n",
    "\n",
    "    sent1=' '.join(sent1.split())\n",
    "\n",
    "    \n",
    "    return sent1,question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(title, code, question):\n",
    "    text = title+\" \"+title+\" \"+title+\" \"+question+\" \"+code\n",
    "    vector = tf1_new.transform([text])\n",
    "    pred = model.predict(vector)\n",
    "\n",
    "    output=[]\n",
    "    for tag,idx in zip(tags,pred.toarray()[0]):\n",
    "        if(idx==1):\n",
    "            output.append(tag)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all models and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags Loaded!\n",
      "Model Loaded!\n",
      "Vectorizer loaded!\n"
     ]
    }
   ],
   "source": [
    "tags=\"\"\n",
    "with open('model/tags_list.txt', 'r') as f:\n",
    "    tags+=(f.read())\n",
    "tags = tags.split()\n",
    "tags = tags[:100]\n",
    "print(\"Tags Loaded!\")\n",
    "\n",
    "with open(\"model/LR_tfidf_3title_question_code_model.pkl\",'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print(\"Model Loaded!\")\n",
    "\n",
    "tf1_vocal = pickle.load(open(\"model/x_tfidf_train_multilabel_vocal.pickle\", 'rb'))\n",
    "tf1_idf = pickle.load(open(\"model/x_tfidf_train_multilabel_idf.pickle\", 'rb'))\n",
    "\n",
    "tf1_new = TfidfVectorizer(min_df=0.00009, max_features=400000, tokenizer = lambda x: x.split(), ngram_range=(1,4), vocabulary=tf1_vocal)\n",
    "tf1_new._tfidf._idf_diag = sp.spdiags(tf1_idf, diags = 0, m = len(tf1_idf), n = len(tf1_idf))\n",
    "\n",
    "print(\"Vectorizer loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking input Title and Body and Predicting Tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Title\n",
      "How to fetch an XML feed using asp.net\n",
      "Enter Body\n",
      "<p>I've decided to convert a Windows Phone 7 app that fetches an XML feed and then parses it to an asp.net web app, using Visual Web Developer Express. I figure since the code already works for WP7, it should be a matter of mostly copying and pasting it for the C# code behind. </p>  <pre><code>HttpWebRequest request = HttpWebRequest.CreateHttp(\"http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&amp;a=sf-muni&amp;r=\" + line1); </code></pre>  <p>That's the first line of code from my WP7 app that fetches the XML feed, but I can't even get HttpWebRequest to work in Visual Web Developer like that. Intellisense shows a create and createdefault, but no CreateHttp like there was in Windows Phone 7. I just need to figure out how to fetch the page, I assume the parsing will be the same as on my phone app. Any help?</p>  <p>Thanks,</p>  <p>Amanda</p>\n",
      "\n",
      "TAGS ASSOCIATED ARE:\n",
      "['c#', 'asp.net']\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter Title\")\n",
    "title = input()\n",
    "print(\"Enter Body\")\n",
    "body = input()\n",
    "\n",
    "title = preprocess_title(title)\n",
    "code,question = preprocess_body(body)\n",
    "\n",
    "output = get_tags(title, code, question)\n",
    "\n",
    "print()\n",
    "print(\"TAGS ASSOCIATED ARE:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to fetch an XML feed using asp.net\n",
    "\n",
    "# <p>I've decided to convert a Windows Phone 7 app that fetches an XML feed and then parses it to an asp.net web app, using Visual Web Developer Express. I figure since the code already works for WP7, it should be a matter of mostly copying and pasting it for the C# code behind. </p>  <pre><code>HttpWebRequest request = HttpWebRequest.CreateHttp(\"http://webservices.nextbus.com/service/publicXMLFeed?command=routeConfig&amp;a=sf-muni&amp;r=\" + line1); </code></pre>  <p>That's the first line of code from my WP7 app that fetches the XML feed, but I can't even get HttpWebRequest to work in Visual Web Developer like that. Intellisense shows a create and createdefault, but no CreateHttp like there was in Windows Phone 7. I just need to figure out how to fetch the page, I assume the parsing will be the same as on my phone app. Any help?</p>  <p>Thanks,</p>  <p>Amanda</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
